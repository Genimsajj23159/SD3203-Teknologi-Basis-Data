**Markdown Teknologi Basis Data**


---



**Nama  : Jasmine Georgina Sekartaji**

**NIM   : 121450159  **

**Kelas : RC **

**Three Ways of Storing and Accessing Lots of Images in Python**

original document: https://realpython.com/storing-images-in-python/

dataset: https://www.cs.toronto.edu/~kriz/cifar.html

# **Setup**

## A Dataset to Play With

We will be working with the CIFAR-10 image dataset, created by the Canadian Institute for Advanced Research. This dataset comprises 60,000 color images, each with a resolution of 32x32 pixels, and these images belong to various object categories such as dogs, cats, and airplanes. Although CIFAR-10 is not an exceptionally large dataset, if we were to use the full TinyImages dataset instead, it would require approximately 400GB of free disk space, which could be a significant limitation.

The credit for creating the CIFAR-10 dataset, as mentioned in chapter 3 of a tech report, goes to Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. When you download and unzip the dataset folder, you will find that the files are not human-readable image files. Instead, the images have been serialized and saved in batches using the cPickle format.





While this article will not delve into the details of the `pickle` or `cPickle` modules, it's worth noting that the Python pickle module offers the advantage of being able to serialize any Python object without requiring additional code or transformations. However, it also has a potential security risk and may not perform well when dealing with large quantities of data.

The provided code snippet unpickles each of the five batch files and loads all the images into a NumPy array, allowing for further processing and analysis.


```python
import numpy as np
import pickle
from pathlib import Path

# Path to the unzipped CIFAR data
data_dir = Path("data/cifar-10-batches-py/")

# Unpickle function provided by the CIFAR hosts
def unpickle(file):
    with open(file, "rb") as fo:
        dict = pickle.load(fo, encoding="bytes")
    return dict

images, labels = [], []
for batch in data_dir.glob("data_batch_*"):
    batch_data = unpickle(batch)
    for i, flat_im in enumerate(batch_data[b"data"]):
        im_channels = []
        # Each image is flattened, with channels in order of R, G, B
        for j in range(3):
            im_channels.append(
                flat_im[j * 1024 : (j + 1) * 1024].reshape((32, 32))
            )
        # Reconstruct the original image
        images.append(np.dstack((im_channels)))
        # Save the label
        labels.append(batch_data[b"labels"][i])

print("Loaded CIFAR-10 training set:")
print(f" - np.shape(images)     {np.shape(images)}")
print(f" - np.shape(labels)     {np.shape(labels)}")
```

After executing the provided code, all the image data from the CIFAR-10 dataset is now loaded into the computer's memory (RAM) and stored in the `images` variable. Additionally, the corresponding metadata or labels for these images are stored in the `labels` variable. With the images and their associated information readily available in memory, you can proceed to manipulate and work with this data as needed. The next step would be to install the necessary Python packages or libraries that will be utilized for the three different methods or techniques you plan to employ for your analysis or processing tasks.

## Setup for Storing Images on Disk

You must configure your system to use the default procedure for storing and retrieving these disk images. This post will presume that you have installed Python 3.x on your machine. Pillow will be used to manipulate the images:


```python
$ pip install Pillow
```

or


```python
$ conda install -c conda-forge pillow
```

It should be noted that PIL, the original Python Imaging Library, is incompatible with Python 3.x and is no longer developed. Pillow and PIL cannot coexist, thus if you have already installed PIL, make sure to uninstall it first.

## Getting Started With LMDB

Because it is quick and makes use of memory-mapped files, LMDB, also known as the "Lightning Database," is an acronym for Lightning Memory-Mapped Database. It is not a relational database, but a key-value store.

The way that LMDB is implemented is as a B+ tree, which is essentially a graph structure that resembles a tree and is kept in memory. Each key-value element is a node, and nodes can have multiple offspring. For quick navigation, nodes on the same level are connected to one another.

Furthermore, the B+ tree's essential parts are configured to match the host operating system's page size, which maximizes performance when accessing any key-value pair in the database. Since this specific point is critical to LMDB high-performance, it has been demonstrated that LMDB efficiency depends on the underlying file system and how it is implemented.

The memory-mapped nature of LMDB is another important factor in its effectiveness. This means that, unlike most other databases, it doesn't require copying anything in memory in order to return direct pointers to the memory addresses of both keys and values.

You can explore with this node insertion visualization after reading this article on B+ trees if you'd like to delve a little deeper into the internal workings of the implementation.

Don't worry if B+ trees don't pique your interest. To use LMDB, you don't need to be very knowledgeable about their internal implementation. The LMDB C library has a Python binding that we will use, and pip may be used to install it:



```python
$ pip install lmdb
```

or


```python
$ conda install -c conda-forge python-lmdb
```

## Getting Started With HDF5

HDF5 is an acronym for Hierarchical Data Format, sometimes known as HDF4 or HDF5. HDF4 is not a concern because HDF5 is the version that is currently being maintained.

It's interesting to note that HDF began as a portable, small scientific data format at the National Center for Supercomputing Applications. You may find out if HDF5 is frequently used by reading NASA's description of it from their Earth Data project.

Two categories of objects are present in HDF files:Groups and Datasets

Groups are made up of other groups or datasets, and datasets are multidimensional arrays. A dataset can contain multidimensional arrays of any size and type, but the dimensions and types must be consistent within the dataset. There must be a homogenous N-dimensional array in every dataset. Nevertheless, you can still obtain the heterogeneity you may require because groups and datasets can be nested:




```python
$ pip install h5py
```

or


```python
$ conda install -c conda-forge h5py
```

# **Storing a Single Image**

To be able to conduct experiments, we can evaluate the performance of different file sizes, ranging from one image to 100,000 images, by factors of 10. We can utilize each image twice to reach 100,000 photographs because our five batches of CIFAR-10 sum up to 50,000 images.

For the researchers to get ready for the experiments, make sure that every method has its own folder with all of the database files and picture files, and store the paths to those directories in variables:



```python
from pathlib import Path

disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")
```

Unless you specifically instruct it to do so, Path does not generate the directories for you automatically:


```python
disk_dir.mkdir(parents=True, exist_ok=True)
lmdb_dir.mkdir(parents=True, exist_ok=True)
hdf5_dir.mkdir(parents=True, exist_ok=True)
```

You may now proceed to performing the real experiments, which include code examples showing you how to use each of the three approaches to do common tasks. The Python standard library contains the timeit module, which we can use to help time the experiments.

While learning the APIs of the various Python packages is not the primary goal of this essay, it is useful to know how they can be used. Along with all the code that was utilized to carry out the storing tests, we will go over the general ideas.


## Storing to Disk

An image, which is presently stored in memory as a NumPy array, serves as our input for this experiment. Initially, you should save it as a.png file to your disk and give it the unique picture ID image_id. The Pillow package that you previously loaded can be used for this:


```python
from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])
```

Through doing this, the picture is saved. The image label, which is the meta data associated with the image in our example dataset, is also important in all practical applications. There are various ways to save the meta data when you store photographs on disk.

Encoding the labels into the image name is one way to solve this. One benefit of this is that it doesn't need any additional files.

Its major drawback, though, is that you have to deal with every file every time you work with labels. You can play with the labels by themselves without loading the photos if you store the labels in an other file. For this experiment, I have the labels saved in different.csv files as seen above.


Let's now proceed to completing the identical task using LMDB.


## Storing to LMDB

First off, since LMDB is a key-value storage system, each entry is recorded as a byte array. In this instance, the image itself will serve as the value, and the keys will provide a unique identifier for each image. Since strings are required for both the keys and the values, it is customary to serialize the value first and then unserialize it when reading it back out.

For the image and its meta data, you can make the following simple Python class:



```python
class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary
        # for this dataset, but some datasets may include images of
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]

        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
```

Second, since LMDB is memory-mapped, new databases must anticipate how much memory they will require. In our situation, this is quite simple, but in other situations—which you will see in greater detail in a later section—it can be a huge hassle. This variable is known as the map_size by LMDB.

Finally, transactions are used to carry out read and write activities with LMDB. They are comparable to those of a conventional database since they are a collection of database operations. Even though it already appears to be much more difficult than the disk version, please continue reading!


Let's examine the code to save a single image to an LMDB while keeping those three things in mind:



```python
import lmdb
import pickle

def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 10

    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)

    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
```

It's a good idea to figure out exactly how many bytes each key-value pair will occupy.

This will be an approximation with a collection of photos of different sizes, but you can use sys.getsizeof() to obtain a decent approximation. Remember that sys.getsizeof(CIFAR_Image) does not return the size of an instantiated object; rather, it simply returns the 1056 size of a class declaration.


Additionally, lists, nested items, and objects with references to other objects will not allow the function to calculate them to their fullest extent.

Alternatively, you could use Pympler to calculate an object's exact size, which would save you some calculations.


## Storing With HDF5

Keep in mind that multiple datasets can be present in an HDF5 file. You can generate two datasets in this rather simple scenario, one for the image and one for its metadata:


```python
import h5py

def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()
```

The particular kind of data that will be saved in the dataset—unsigned 8-bit integers in this case—is specified by the file h5py.h5t.STD_U8BE. A complete list of HDF's predefined datatypes is available here.


Note: It is recommended to select your minimum requirements because the datatype you choose will have a significant impact on HDF5's runtime and storage needs.

## Experiments for Storing a Single Image

At this point, all three functions for storing a single image can be added to a dictionary so that they can be used at a later time for the timing experiments:


```python
_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)
```

Everything is now prepared to carry out the timed experiment. Try storing the first image from CIFAR together with its label in each of the following three methods:


```python
from timeit import timeit

store_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

Note: You can get a MapFullError: mdb_txn_commit: MDB_MAP_FULL: Environment mapsize limit reached error when tinkering with LMDB. It's crucial to understand that, even when two values have the same key, LMDB does not replace the earlier values.

This speeds up write times, but it also implies that you will take up more map space if you store a picture in an LMDB file more than once. Make sure that any previous LMDB files are deleted before performing a store function.




Here are two things to remember:


*   Every method is incredibly fast.
*   LMDB utilizes more disk space than other databases.

It's evident that even if LMDB performs slightly better, nobody has been persuaded to use disk storage instead of pictures. You may open and see them from any file system browser, and they are in a format that is readable by humans! Now let's take a closer look at a lot more pictures.


# **Storing Many Images**

## Adjusting the Code for Many Images

It is simple to save numerous photos as PNG files by just invoking store_single_method() more than once. However, since you don't want a new database file for every image, this isn't true for LMDB or HDF5. Instead, you should combine every image into one or more files.

The code will need to be somewhat modified, and three additional functions,store_many_disk(), store_many_lmdb(), and store_many_hdf5 that take multiple pictures must be created:



```python
store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Same as before — but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()
```

The image files method was changed to loop over each image in the list so you may store multiple images to disk. Since we are generating a CIFAR_Image object for every image and its meta data, LMDB also requires a loop.

The HDF5 approach requires the least amount of tweaking. Actually, not much of an adjustment is made at all! As before, all the photos were crammed into a single dataset because HFD5 files have no size constraints other than those imposed by external factors or dataset size.


## Preparing the Dataset

Let's first double the size of our dataset so that we can test with up to 100,000 photographs before repeating the experiments:





```python
cutoffs = [10, 100, 1000, 10000, 100000]

# Let's double our images so that we have 100,000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Make sure you actually have 100,000 images and labels
print(np.shape(images))
print(np.shape(labels))
```

## Experiment for Storing Many Images

You may build a dictionary using store_many_ that handles all the functions and do the following experiments, just like you did with reading a lot of images:


```python
_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)

from timeit import timeit

store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")
```

Assuming you choose to follow along and execute the code yourself, prepare to be patient for a short while as 111,110 photos are stored to your disk in three distinct formats, each three times. Additionally, you'll have to part up about 2 GB of disk space.



The first graph, which displays the typical, unadjusted storage time, makes clear how much LMDB or HDF5 storage differs significantly from that of.png files.



The second graph, which displays the timing log, demonstrates how HDF5 initially performs slower than LMDB but gradually outperforms it when dealing with higher picture counts.


This is why LMDB and HDF5 are something to consider, even though the precise outcomes may differ based on your computer. The code that produced the graph above is as follows:


```python
import matplotlib.pyplot as plt

def plot_with_legend(
    x_range, y_data, legend_labels, x_label, y_label, title, log=False
):
    """ Displays a single plot with multiple datasets and matching legends.
        Parameters:
        --------------
        x_range         list of lists containing x data
        y_data          list of lists containing y values
        legend_labels   list of string legend labels
        x_label         x axis label
        y_label         y axis label
    """
    plt.style.use("seaborn-whitegrid")
    plt.figure(figsize=(10, 7))

    if len(y_data) != len(legend_labels):
        raise TypeError(
            "Error: number of data sets does not match number of labels."
        )

    all_plots = []
    for data, label in zip(y_data, legend_labels):
        if log:
            temp, = plt.loglog(x_range, data, label=label)
        else:
            temp, = plt.plot(x_range, data, label=label)
        all_plots.append(temp)

    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(handles=all_plots)
    plt.show()

# Getting the store timings data to display
disk_x = store_many_timings["disk"]
lmdb_x = store_many_timings["lmdb"]
hdf5_x = store_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Storage time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Log storage time",
    log=True,
)
```

# **Reading a Single Image**

## Reading From Disk

Due of the serialization phase, LMDB requires the most work out of the three approaches when reading image files back out of memory. Let us examine these functions, which extract one image for every one of the three storage types.

Read one picture and its metadata from a.png and.csv file first:



```python
def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))

    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])

    return image, label
```

## Reading From LMDB

Next, access the environment and initiate a read transaction to retrieve the identical image and meta from an LMDB:



```python
def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()

    return image, label
```

Here are some things to keep in mind with the aforementioned code snippet:


* Line 13: The readonly=True flag indicates that until the transaction is complete, no writes are permitted on the LMDB file. It is the same as taking a read lock in database terminology.
* Line 20: You must undo the actions we made to pickle the CIFAR_Image object during its writing in order to retrieve it. This is where the object's get_image() function comes in handy.

This completes the process of retrieving the image from LMDB. Lastly, you should apply HDF5 in the same way.

## Reading From HDF5

The process of reading from HDF5 seems a lot like writing. The following code opens, reads, and parses the HDF5 file to extract the same image and meta data:


```python
def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")

    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))

    return image, label
```

It might be noted that in order to access the different datasets contained in the file, index the file object using the dataset name before a forward slash (/). You can still make a dictionary with all of the read functions in it:


```python
_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)
```

## Experiment for Reading a Single Image

Given that the experiment code for reading a single image in is as follows, you may expect the results to be rather trivial:


```python
from timeit import timeit

read_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

The experiment's findings for reading a single image are as follows:


The.png and.csv files can be read directly from disk a little faster, but all three approaches operate quite quickly. Our upcoming experiments will be far more fascinating.




# **Reading Many Images**

## Adjusting the Code for Many Images

By extending the functions mentioned previously, you can utilize read_many_ to develop functions that will be useful for the upcoming experiments. As before, comparing performance when reading varying numbers of images—which are replicated in the code below for reference—is intriguing.





```python
def read_many_disk(num_images):
    """ Reads image from disk.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Loop over all IDs and read each image in one by one
    for image_id in range(num_images):
        images.append(np.array(Image.open(disk_dir / f"{image_id}.png")))

    with open(disk_dir / f"{num_images}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in reader:
            labels.append(int(row[0]))
    return images, labels

def read_many_lmdb(num_images):
    """ Reads image from LMDB.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Read all images in one single transaction, with one lock
        # We could split this up into multiple transactions if needed
        for image_id in range(num_images):
            data = txn.get(f"{image_id:08}".encode("ascii"))
            # Remember that it's a CIFAR_Image object
            # that is stored as the value
            cifar_image = pickle.loads(data)
            # Retrieve the relevant bits
            images.append(cifar_image.get_image())
            labels.append(cifar_image.label)
    env.close()
    return images, labels

def read_many_hdf5(num_images):
    """ Reads image from HDF5.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "r+")

    images = np.array(file["/images"]).astype("uint8")
    labels = np.array(file["/meta"]).astype("uint8")

    return images, labels

_read_many_funcs = dict(
    disk=read_many_disk, lmdb=read_many_lmdb, hdf5=read_many_hdf5
)
```

## Experiment for Reading Many Images

The experiment to read out numerous photos can now be conducted:


```python
from timeit import timeit

read_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_read_many_funcs[method](num_images)",
            setup="num_images=cutoff",
            number=1,
            globals=globals(),
        )
        read_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, No. images: {cutoff}, Time usage: {t}")
```

You may graph the read experiment data, same as we did before:





The top graph illustrates the typical, unadjusted read times and highlights the significant discrepancy in read speeds between LMDB or HDF5 and.png files.

On the other hand, the graph at the bottom highlights the relative differences with fewer photos by displaying the log of the timings. In particular, we can observe that HDF5 regularly outperforms LMDB by a tiny margin after initially lagging behind.


**In actuality, the read time is frequently more important than the write time.** Consider a scenario where you have to train a deep neural network using just half of the image dataset that can fit in RAM at once. The complete dataset is needed for each epoch of network training, and the model requires several hundred epochs to converge. Every epoch, you will effectively be reading half of the dataset into memory.

You get the idea, albeit there are a few strategies people use to make this slightly better, such training pseudo-epochs.


Take another look at the read graph above now. You may wait forty minutes or six hours for your model to train based on the difference between a 40-second and 4-second read time!




The following is what we get when we look at the read and write times on the same chart:



The write and read timings differ significantly when storing images as PNG files. With LMDB and HDF5, on the other hand, the distinction is far less obvious. Overall, there is a compelling case to be made for storing photos in LMDB or HDF5, even though read time is more important than write time.

# **Considering Disk Usage**

There are other performance metrics besides speed that you could find useful. Disk space is a legitimate and pertinent problem, especially because we are already working with very huge datasets.

Assume you own a 3 terabyte image dataset. Unlike our CIFAR example, you presumably already have them on disk somewhere, so utilizing an other storage technique is really just creating a copy of them, which needs to be saved as well. When you employ the pictures, doing so will greatly improve performance; however, you must ensure that you have sufficient disk space.

**How much disk space do the various storage methods use?**



When storing regular.png images, less disk space is used by HDF5 and LMDB. It's vital to remember that the operating system **and—more importantly—the volume of data you store are two major determinants of both LMDB and HDF5 disk utilization and performance.**

The effectiveness of LMDB is derived from caching and utilizing OS page sizes. You don't have to know how it operates inside, but be aware that **larger photos will require a lot more disk space when using LMDB** since they won't fit on the leaf pages, which are the standard storage locations in the tree; instead, you'll have a lot of overflow pages. In the chart above, the LMDB bar will explode off the page.

Our 32x32x3 pixel images allow for excellent LMDB performance and are quite modest when compared to average photos you may utilize.

Based on the experience, HDF5 is typically marginally more disk-efficient than LMDB when dealing with images that have 256x256x3 or 512x512x3 pixels, but we won't investigate this empirically here. This serves as a smooth introduction to the last portion, which is a qualitative analysis of the variations in the approaches.



# **Conclusion**


---


 From the article, there are about three methods   for storing and retrieving a large number of photos in Python, and you may have even had an opportunity to experiment with some of them. This article's whole code is available as a Python script here or as a Jupyter notebook here. Proceed at your own peril, as tiny square pictures of automobiles, boats, and other objects will fill up several GB of your disk space.

You've seen examples of how different storage strategies can significantly impact read and write times, as well as some advantages and disadvantages of the three strategies this article looks at. Although it may seem most obvious to store photos as.png files, there are significant speed advantages to using techniques like HDF5 or LMDB.

**The ideal storage strategy will rely on your particular dataset and use cases; there is no perfect solution.**

